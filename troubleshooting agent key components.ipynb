{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bee33ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'laptop', 'is', 'overheating', 'after', 'the', 'latest', 'update', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample query\n",
    "query = \"My laptop is overheating after the latest update.\"\n",
    "\n",
    "# Tokenize the query\n",
    "tokens = word_tokenize(query)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ab8b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words and their POS Tags:\n",
      "Natural: JJ\n",
      "language: NN\n",
      "processing: NN\n",
      "enables: VBZ\n",
      "computers: NNS\n",
      "to: TO\n",
      "understand: VB\n",
      "human: JJ\n",
      "language: NN\n",
      ".: .\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "# Sample text\n",
    "text = \"Natural language processing enables computers to understand human language.\"\n",
    "\n",
    "# Tokenize text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Apply POS tagging\n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "# Print words with their POS tags\n",
    "print(\"Words and their POS Tags:\")\n",
    "for word, tag in pos_tags:\n",
    "    print(f\"{word}: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e829b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$'), ('laptop', 'NN'), ('is', 'VBZ'), ('overheating', 'VBG'), ('after', 'IN'), ('the', 'DT'), ('latest', 'JJS'), ('update', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Apply POS tagging to the tokens\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "print(tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63963fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities, their Labels, and Descriptions:\n",
      "Apple: ORG (Companies, agencies, institutions, etc.)\n",
      "San Francisco: GPE (Countries, cities, states)\n",
      "$1 billion: MONEY (Monetary values, including unit)\n",
      "Tim Cook: PERSON (People, including fictional)\n",
      "New York: GPE (Countries, cities, states)\n",
      "April 25, 2023: DATE (Absolute or relative dates or periods)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Apple is looking at buying a startup in San Francisco for $1 billion. Tim Cook attended a meeting in New York on April 25, 2023.\"\n",
    "\n",
    "# Process text through the model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Perform Named Entity Recognition\n",
    "print(\"Named Entities, their Labels, and Descriptions:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}: {ent.label_} ({spacy.explain(ent.label_)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d86be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "San Francisco GPE\n",
      "$1 billion MONEY\n",
      "Tim Cook PERSON\n",
      "New York GPE\n",
      "April 25, 2023 DATE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the pre-trained model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Apply NER to the query\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the identified entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d7da00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check your cooling system, clean the fans, and ensure proper ventilation.\n"
     ]
    }
   ],
   "source": [
    "# Sample knowledge base\n",
    "knowledge_base = {\n",
    "    \"overheating\": \"Check your cooling system, clean the fans, and ensure proper ventilation.\",\n",
    "    \"slow performance\": \"Close unnecessary applications, restart your system, and check for malware.\"\n",
    "}\n",
    "\n",
    "# Function to retrieve a solution\n",
    "def get_solution(issue):\n",
    "    return knowledge_base.get(issue, \"No solution found for this issue.\")\n",
    "\n",
    "# Example usage\n",
    "print(get_solution(\"overheating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a2c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:55:39.517562: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-03 20:55:39.651823: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756925739.692852  117757 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756925739.705513  117757 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756925739.792878  117757 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756925739.792900  117757 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756925739.792902  117757 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756925739.792903  117757 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-03 20:55:39.805913: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Result:\n",
      "Label: POSITIVE, Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Sample text for sentiment analysis\n",
    "text = \"I'm so happy with the excellent service and support I received!\"\n",
    "\n",
    "# Analyze sentiment\n",
    "result = sentiment_analyzer(text)\n",
    "\n",
    "# Display result\n",
    "print(\"Sentiment Analysis Result:\")\n",
    "for res in result:\n",
    "    print(f\"Label: {res['label']}, Confidence: {res['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea686c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Sentiment Analysis Results:\n",
      "Text: 'I absolutely love this product!' | Sentiment: POSITIVE (Confidence: 1.00)\n",
      "Text: 'This experience was terrible and disappointing.' | Sentiment: NEGATIVE (Confidence: 1.00)\n",
      "Text: 'The quality is okay, not great but not bad.' | Sentiment: POSITIVE (Confidence: 1.00)\n"
     ]
    }
   ],
   "source": [
    "# Sample batch of texts\n",
    "texts = [\n",
    "    \"I absolutely love this product!\",\n",
    "    \"This experience was terrible and disappointing.\",\n",
    "    \"The quality is okay, not great but not bad.\"\n",
    "]\n",
    "\n",
    "# Analyze sentiment for each text in the list\n",
    "results = sentiment_analyzer(texts)\n",
    "\n",
    "# Display results for each text\n",
    "print(\"Batch Sentiment Analysis Results:\")\n",
    "for text, res in zip(texts, results):\n",
    "    print(f\"Text: '{text}' | Sentiment: {res['label']} (Confidence: {res['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b19f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check your cooling system, clean the fans, and ensure proper ventilation.\n"
     ]
    }
   ],
   "source": [
    "def troubleshoot(query):\n",
    "    if \"overheating\" in query.lower():\n",
    "        return get_solution(\"overheating\")\n",
    "    elif \"slow\" in query.lower():\n",
    "        return get_solution(\"slow performance\")\n",
    "    else:\n",
    "        return \"Can you provide more details about the issue?\"\n",
    "\n",
    "# Example usage\n",
    "response = troubleshoot(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa99a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

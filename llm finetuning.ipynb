{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8787f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0    The staff was very kind and attentive to my ...      2   \n",
      "1  The waiting time was too long, and the staff w...      0   \n",
      "2  The doctor answered all my questions...but the...      1   \n",
      "3  The nurse was compassionate & made me feel com...      2   \n",
      "4  I had to wait over an hour before being seen. ...      0   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  the staff was very kind and attentive to my needs  \n",
      "1  the waiting time was too long and the staff wa...  \n",
      "2  the doctor answered all my questionsbut the fa...  \n",
      "3  the nurse was compassionate  made me feel comf...  \n",
      "4  i had to wait over an hour before being seen  ...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "# Example dataset (replace with your own if you want)\n",
    "data_dict = {\n",
    "    \"text\": [\n",
    "        \"  The staff was very kind and attentive to my needs!!!  \",\n",
    "        \"The waiting time was too long, and the staff was rude. Visit us at http://hospitalreviews.com\",\n",
    "        \"The doctor answered all my questions...but the facility was outdated.   \",\n",
    "        \"The nurse was compassionate & made me feel comfortable!! :) \",\n",
    "        \"I had to wait over an hour before being seen.  Unacceptable service! #frustrated\",\n",
    "        \"The check-in process was smooth, but the doctor seemed rushed. Visit https://feedback.com\",\n",
    "        \"Everyone I interacted with was professional and helpful.  \"\n",
    "    ],\n",
    "    \"label\": [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\", \"positive\"]\n",
    "}\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "data = pd.DataFrame(data_dict)\n",
    "\n",
    "# Clean the text\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower().strip()  # Convert to lowercase and remove extra spaces\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove special characters\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "data[\"cleaned_text\"] = data[\"text\"].apply(clean_text)\n",
    "\n",
    "# Convert labels to numerical values\n",
    "data[\"label\"] = data[\"label\"].astype(\"category\").cat.codes  # Converts [\"positive\", \"negative\", \"neutral\"] to [0, 1, 2]\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277917fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Apply tokenization with padding\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Apply tokenization\n",
    "data[\"tokenized\"] = data[\"cleaned_text\"].apply(tokenize_function)\n",
    "\n",
    "# Extract tokenized features\n",
    "data[\"input_ids\"] = data[\"tokenized\"].apply(lambda x: x[\"input_ids\"])\n",
    "data[\"attention_mask\"] = data[\"tokenized\"].apply(lambda x: x[\"attention_mask\"])\n",
    "\n",
    "# Drop old tokenized column\n",
    "data = data.drop(columns=[\"tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ff71c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The staff was very kind and attentive to my ...</td>\n",
       "      <td>2</td>\n",
       "      <td>the staff was very kind and attentive to my needs</td>\n",
       "      <td>[101, 1996, 3095, 2001, 2200, 2785, 1998, 2012...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The waiting time was too long, and the staff w...</td>\n",
       "      <td>0</td>\n",
       "      <td>the waiting time was too long and the staff wa...</td>\n",
       "      <td>[101, 1996, 3403, 2051, 2001, 2205, 2146, 1998...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The doctor answered all my questions...but the...</td>\n",
       "      <td>1</td>\n",
       "      <td>the doctor answered all my questionsbut the fa...</td>\n",
       "      <td>[101, 1996, 3460, 4660, 2035, 2026, 3980, 8569...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The nurse was compassionate &amp; made me feel com...</td>\n",
       "      <td>2</td>\n",
       "      <td>the nurse was compassionate  made me feel comf...</td>\n",
       "      <td>[101, 1996, 6821, 2001, 29353, 2081, 2033, 251...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had to wait over an hour before being seen. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i had to wait over an hour before being seen  ...</td>\n",
       "      <td>[101, 1045, 2018, 2000, 3524, 2058, 2019, 3178...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0    The staff was very kind and attentive to my ...      2   \n",
       "1  The waiting time was too long, and the staff w...      0   \n",
       "2  The doctor answered all my questions...but the...      1   \n",
       "3  The nurse was compassionate & made me feel com...      2   \n",
       "4  I had to wait over an hour before being seen. ...      0   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  the staff was very kind and attentive to my needs   \n",
       "1  the waiting time was too long and the staff wa...   \n",
       "2  the doctor answered all my questionsbut the fa...   \n",
       "3  the nurse was compassionate  made me feel comf...   \n",
       "4  i had to wait over an hour before being seen  ...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 1996, 3095, 2001, 2200, 2785, 1998, 2012...   \n",
       "1  [101, 1996, 3403, 2051, 2001, 2205, 2146, 1998...   \n",
       "2  [101, 1996, 3460, 4660, 2035, 2026, 3980, 8569...   \n",
       "3  [101, 1996, 6821, 2001, 29353, 2081, 2033, 251...   \n",
       "4  [101, 1045, 2018, 2000, 3524, 2058, 2019, 3178...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd70dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.016659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.026258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.030307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=1.0586927731831868, metrics={'train_runtime': 3.8011, 'train_samples_per_second': 3.946, 'train_steps_per_second': 0.789, 'total_flos': 986675316480.0, 'train_loss': 1.0586927731831868, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
    "\n",
    "#print(train_dataset)\n",
    "\n",
    "# Enable dynamic padding for batches\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",  \n",
    "    save_strategy=\"epoch\",  \n",
    "    eval_strategy=\"epoch\",  \n",
    ")\n",
    "# Load pre-trained BERT model (3-class classification)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947eedc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5, F1 Score: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Generate predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = test_dataset['label']\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447330ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
